---
title: GPU 硬件架构简要剖析
catalog: true
comments: true
indexing: true
header-img: ../../../../img/default.jpg
top: false
tocnum: true
date: 2021-08-08 16:18:14
subtitle:
tags:
- cuda
categories:
---
> 这篇文章主要介绍一下GPU底层的硬件架构以及GPU存储体系，为之后学习cuda编程打好基础。本文首先会对比CPU体系架构和GPU体系架构，看看它们分别适用于什么场景，为什么需要GPU以及GPU的设计原则。接着简单介绍下CPU体系架构，之后引入GPU体系架构，了解GPU在CPU的基础上增加了什么、减少了什么，以及为啥要这样裁剪。最后一起看下Nvidia系列的某些具体GPU芯片。

# 为什么需要GPU？
我们知道，cpu作为计算机的核心与大脑，它即负责程序的控制逻辑，也负责数据计算。作为通用处理器，一般来说CPU啥都能做，那为啥还需要GPU呢？原因是CPU本质还是通用处理器，他需要处理所有的场景，不能偏科，所以CPU还是以控制逻辑为主，计算只是他的一部分。CPU擅长处理逻辑复杂但计算量相对较小的业务逻辑，他是控场大师，是政治家，运筹帷幄，合纵连横，不做莽夫的事情。

而GPU不一样，GPU创立之初就是为了处理那些逻辑简单但计算量庞大的任务，例如大规模矩阵乘法这种大量的乘法和加法操作，它不会面对if else switch等判断跳转逻辑。GPU是实干家，他不会过多的去考虑那些有的没的，就是疯狂的干活。这种职责定位也导致了GPU不需要像CPU那样有复杂的分支预测、旁路预取等等控制逻辑，取而代之的是，将这些控制逻辑腾出来的空间统统用于计算。

**国务院(CPU)vs码头工厂(GPU)**
我们拿生活中场景类比一下，CPU可以看做一个国家的中央决策机构，它需要考虑的事情太多太复杂了，要兼顾国内、国外、经济、政治、文化等等一些乱七八糟的事务，这些事情繁琐复杂，因此需要配置强大的智能团，要考虑各种可能性，做多手准备。
相反，GPU可以看做是码头工厂，他每天要做的事情就是搬运货物，简单且重复，有砖就搬，没有就休息，才不会考虑外面是否洪水滔天。作为工厂老板，唯一要考虑的就是如何招更多的工人，如何修更宽的道路运送货物。对应到GPU架构中，则是如何塞更多的core，如何设计更高的显存带宽。

总而言之
- CPU是通用处理器，其**设计原则就是对于各式各样的场景都能应付自如**，所以cpu芯片内部很大一部分适用于控制逻辑和L3缓存的。
- GPU是异构(相对于CPU采用不同的架构)的处理器，其**设计原则就是尽可能提高计算吞吐量**，适用场景为简单、重复但计算量大的任务，其控制逻辑很少，计算单元超多。

# CPU体系架构简介
我们先简单介绍一下CPU的体系架构，看看它为什么不擅长做重复计算，以及如何改造才能获取更好的计算性能。

![此处输入图片的描述][1]

上图是一个overview，我们仔细看下CPU芯片的物理结构图，如下：
![此处输入图片的描述][2]

我们可以看到，在CPU芯片内部，真正做计算的core一共就8个，其占整个芯片的面积大概不到40%，芯片面积主要给了L3缓存以及缓存控制器，即便是core，其中真正做计算的Alu也是比较少的。为什么会这样设计呢？原因就是因为cpu是以控制逻辑为主。我们知道，为了提高ipc，cpu引入了流水线，流水线本身是会增加延时以及芯片面积的，而为了保证流水线的有效性，又增加了许多额外的控制电路，例如分支预测、分支断定、旁路电路等，这些电路又挤占了真正干活的alu空间，导致cpu计算性能其实并不高。

如果面对例如科学计算这些计算量奇高，但逻辑并不复杂甚至可以说单一的任务，cpu就明显力不从心了。那应该怎么做呢？思路很简单，但就是打造”血汗工厂“，可以从以下三个方面着手：

- **精兵简政**：首先因为任务是计算密集型的，逻辑相对简单，因此可以把那些占地面积大，又不干活的“臃肿”的控制机构统统去掉，全部换为计算单元，只留下几个包工头。由之前的几个、十几个核心增加到几百个，上千个核心。
- **要想富，广修路**：算力提升了，但数据还不够，不能白白浪费劳力呀。因此需要提升显存与计算单元的通信带宽，由之前的4车道改为16车道甚至32车道，同时扩大仓库，这样工人们就不会处于无活可干的处境了。
- **996、007**：即便工人与货物够了，工厂还可能面临工人找借口偷懒的情况，例如计算core有时说数据还没有准备好，无法干活(指令间的数据依赖)。为了极度压榨工人价值，血汗工厂借鉴了多线程的思路，一个计算单元如果A任务pending了，就分配B任务给它，类似于超卖，让工人总有干不完的活。

以上三点思路解释得比较通俗，我们具体看下GPU是如何实现以上3个指导方针的。

# GPU体系架构简介
从这一节开始我们会比较系统的介绍GPU体系架构。为了更好的理解，我们还是把GPU比作血汗工厂。首先我们列出一些相关的专业名词，看不懂没有关系，后文都会出更详细的解释与定义：
> - **流处理器**（stream processor，SP）：也称为core，是GPU运算的最基本单元，类似于计算机组成课程中的CPU内部的ALU（不严谨），是执行计算的，是最普通，工厂中数目最多的工人。
- **渲染核**：（shader core：SP）：SP的另一个名称，或者说是SP的升级版，称为CUDA core，始于Fermi架构，你可以理解为经过科技升级，工种从民兵升级为剑士，变得更强。但是功能一样。
- **双精度浮点运算单元**（DP）：专用于双精度浮点运算的处理单元，一种特殊工种，只能用于双精度浮点运算。
- **特殊功能单元**（special function unit，SFU）:用来执行超越函数指令，如sin,cos 倒数，平方根等函数，另一种强大而又特殊的工种。
- **流处理器**（stream multiprocessors，SM）：从英文名字就可以理解出来，流处理器的集合，是GPU架构中的基本计算单元，可以理解为工厂架构中的车间，，由SP，DP，SFU等运算单元组成（DP和SFU是其他工种）。
- **SMX**：Kepler架构中的SM。
- **SMM**：Maxwell架构中的SM。
- **线程处理器簇**（thread processing cluster，TPC），由SM控制器，多个SM和L1cache（L1缓存）组成。可以理解为工厂架构中部门，其中L1cache为一个多个SM公用的缓存，可以理解为多个车间公用的一个小仓库，存有一些必要的数据，避免了总是去全局总仓库取物品的时间浪费。（学过计算机组成的同学可能很好理解）。
- **图形处理器簇**（graph processing cluster，GPC）：类似与TPC，可以理解为工厂架构中的部门，但是不是TPC的替代品，再Pascal架构中，同时出现了GPC和TPC，且GPC包含TPC，可以理解为一级部门和二级部门。但是有的架构中没有TPC，有的架构中没有GPC，有的架构中TPC，GPC都没有，有的架构中TPC，GPC都有。说到底，部门这个概念本身就很弱，你可以把两个车间分配为一个部门，可以三个车间分配为一个部门。今天你可能和你对面的妹纸是一个部门的，明天可能由于组织架构调整，就和她不是一个部门了，但是她还是坐在你的对面。
- **流处理器阵列**（scalable streaming processor array，SPA）：所有处理器核心和高速缓存的综合，包含所有的SM，TPC，GPC.与存储系统共同构成GPU架构。也就是说，这里把所有的车间，和车间之间公用的小仓库（小仓库认为属于车间或多个车间共同私有），有一个算一个，都加起来，称为SPA，类似于全体生产部门，那么，整个工厂由全体生产部门+仓库构成。
- **存储控制器**（memory controller,MMC）顾名思义，控制存储访问单元，我们可以想象每次从总仓库去取物品，都需要一个指挥，一个运输小车，一个工人专程开车去取。MMC就是这个指挥官。
- **存取单元**（load/store unites，LD/ST）。运输小车？


# GPU存储架构简介
# Nvidia GPU芯片简介


  [1]:  https://common-1256796170.cos.ap-nanjing.myqcloud.com/blog/melon_park/computer-overview.png
  [2]: https://common-1256796170.cos.ap-nanjing.myqcloud.com/blog/melon_park/i7CpuLayout.png
